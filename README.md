
# ðŸ§  Postpartum Depression Detection App

This Flask-based web application helps detect **postpartum depression** using both **MCQ questionnaire responses** and **audio analysis**. It uses pre-trained deep learning models to make predictions based on user input.

---

## ðŸš€ Features

- MCQ-based depression screening using a trained neural network
- Audio analysis using speech features (MFCC, Chroma, etc.)
- Final decision based on combined MCQ and Audio model outputs
- Web interface for users to submit data
- Real-time results with predictions

---

## ðŸ›  Requirements

Install Python packages using:

```bash
pip install -r requirements.txt
````

Required tools:

* Python 3.8 or above
* FFmpeg (for audio conversion)

To install **FFmpeg**:

* **Windows**: Download from [https://ffmpeg.org/download.html](https://ffmpeg.org/download.html) and add it to your system PATH.
* **Linux (Debian/Ubuntu)**: `sudo apt install ffmpeg`
* **MacOS**: `brew install ffmpeg`

---

## ðŸ“‚ Project Structure

```plaintext
Postpartum-depression/
â”‚
â”œâ”€â”€ app3.py                      # Main Flask app
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md                   # This file
â”‚
â”œâ”€â”€ templates/                  # HTML templates for web app
â”‚   â”œâ”€â”€ home.html
â”‚   â”œâ”€â”€ questionnaire.html
â”‚   â”œâ”€â”€ audio_analysis.html
â”‚   â””â”€â”€ result.html
â”‚
â”œâ”€â”€ models/                     # Pre-trained ML models
â”‚   â”œâ”€â”€ mcq_model.h5
â”‚   â”œâ”€â”€ audio_model.h5
â”‚   â””â”€â”€ fusion_model.h5
â”‚
â”œâ”€â”€ data/                       # CSV dataset for scaling
â”‚   â”œâ”€â”€ integrated_dataset.csv
â”‚   â””â”€â”€ sample_audio.wav
â”‚
â”œâ”€â”€ uploads/                    # Uploaded and converted audio files
â”‚   â”œâ”€â”€ audio.webm
â”‚   â””â”€â”€ audio.wav
â”‚
â”œâ”€â”€ scripts/                    # Extra scripts for training/evaluation
â”‚   â”œâ”€â”€ evaluate_model.py
â”‚   â”œâ”€â”€ extract_audio_features.py
â”‚   â”œâ”€â”€ ml_predict.py
â”‚   â”œâ”€â”€ predict_depression.py
â”‚   â””â”€â”€ (more...)
```

---

## ðŸ“¦ How to Run the Web App

1. Make sure you have all the required models and `integrated_dataset.csv` in place.

2. Run the Flask app:

```bash
python app.py
```

3. Open your browser and go to:

```
http://127.0.0.1:5000/
```

4. Use the MCQ form or upload audio to get predictions.

---

## ðŸ§ª How to Run CLI Testing Script

You can also test predictions directly via command line using one of your scripts (like `predict_depression.py`):

```bash
python predict_depression.py
```

* Choose:

  * `1` for MCQ-based test
  * `2` for Audio-only
  * `3` for Fusion (both MCQ & audio)
* Make sure `test_audio.wav` is placed inside the correct directory (`uploads/` or path used in script)

---

## ðŸ” How It Works

* **MCQ Model**: Takes scaled questionnaire inputs and outputs a depression score.
* **Audio Model**: Extracts features like MFCCs, Chroma, Spectral Centroid, Zero-Crossing Rate using Librosa.
* **Fusion Model**: Combines both MCQ and audio data for a more reliable prediction.
* Each model outputs a value which is interpreted as:

  * `Not Depressed` if score â‰¤ 1
  * `Depressed` if score > 1

---

## ðŸ§ª Experimental / Unused Code

This project includes some **test files**, **experimental scripts**, or **older model versions** that are not used directly in the main app.

These include:

* `scripts/`: training, testing, model evaluation, and feature extraction scripts
* Extra models like `best_model.h5`, `fine_tune_model.py`, etc.
* Unused datasets or audio samples in `data/`

These files are retained for:

* Debugging
* Reproducibility
* Further experimentation

You can ignore them if you're just running the app, but feel free to explore them if you're interested in model training or backend logic.

---

## ðŸ“§ Contact

Feel free to reach out if you have questions or want to contribute!

```

---


```
